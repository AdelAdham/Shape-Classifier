{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltim\n",
    "from PIL import Image as im\n",
    "import numpy as np\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "[[[ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((2, 2))\n",
    "print(a)\n",
    "b = a.reshape((2, 2, 1))\n",
    "print(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(256, 256, 4)\n",
      "(256, 256)\n",
      "(28, 28)\n",
      "<class 'PIL.BmpImagePlugin.BmpImageFile'>\n",
      "<class 'PIL.Image.Image'>\n",
      "<class 'numpy.ndarray'>\n",
      "(28, 28)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#====Trials\n",
    "img = pltim.imread(\"Ellipse_TS/ellipse1.bmp\", format=\"bmp\")\n",
    "print(type(img))\n",
    "print(img.shape)\n",
    "\n",
    "img2 = im.open(\"Ellipse_TS/ellipse1.bmp\")\n",
    "# imgplt2 = plt.pyplot.imshow(img2)\n",
    "# print(img2)\n",
    "img2.show()\n",
    "print(img2.size)\n",
    "img2.thumbnail((28,28))\n",
    "print(img2.size)\n",
    "img2.show()\n",
    "gray_img = img2.convert('L')\n",
    "gray_img.show()\n",
    "# print(gray_img.shape)\n",
    "\n",
    "\n",
    "# convtonp =  np.ndarray([28, 28, 1])\n",
    "convtonp = np.array(gray_img)\n",
    "\n",
    "imgF = img.flatten() \n",
    "print(type(img2))\n",
    "print(type(gray_img))\n",
    "print(type(convtonp))\n",
    "print(convtonp.shape)\n",
    "c = convtonp.reshape((28, 28, 1))\n",
    "print(c.shape)\n",
    "# print(c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 28, 28, 1)\n",
      "255\n",
      "(28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#reading images and data adjustment\n",
    "all_photos =  np.ndarray([255, 28, 28, 1])#85*3, photo dims\n",
    "all_photos_names =  []\n",
    "print(all_photos.shape)\n",
    "\n",
    "#reading Lines\n",
    "for i, filename in enumerate(os.listdir(\"Line_TS\")):   \n",
    "    tmp = im.open(\"Line_TS/\" + filename)\n",
    "    tmp.thumbnail((28,28))\n",
    "    tmp2 = np.array(tmp.convert('L'))\n",
    "    all_photos[i] = tmp2.reshape((28,28,1))\n",
    "    all_photos_names.append(filename)\n",
    "\n",
    "#reading Ellipse\n",
    "for i, filename in enumerate(os.listdir(\"Ellipse_TS\")):\n",
    "    tmp = im.open(\"Ellipse_TS/\" + filename)\n",
    "    tmp.thumbnail((28,28))\n",
    "    tmp2 = np.array(tmp.convert('L'))\n",
    "    all_photos[i+85] = tmp2.reshape((28,28,1))\n",
    "    all_photos_names.append(filename)\n",
    "    \n",
    "#reading Diamonds\n",
    "for i, filename in enumerate(os.listdir(\"Diamond_TS\")):\n",
    "    tmp = im.open(\"Diamond_TS/\" + filename)\n",
    "    tmp.thumbnail((28,28))\n",
    "    tmp2 = np.array(tmp.convert('L'))\n",
    "    all_photos[i+170] = tmp2.reshape((28,28,1))\n",
    "    all_photos_names.append(filename)\n",
    "\n",
    "print(len(all_photos_names))\n",
    "img2 = im.open(\"Line_TS/\" + all_photos_names[0])\n",
    "img2.show()\n",
    "print(all_photos[0].shape)\n",
    "print(type(all_photos[0]))\n",
    "\n",
    "img2 = im.open(\"Ellipse_TS/\" + all_photos_names[85])\n",
    "img2.show()\n",
    "print(all_photos[85].shape)\n",
    "print(type(all_photos[85]))\n",
    "\n",
    "img2 = im.open(\"Diamond_TS/\" + all_photos_names[170])\n",
    "img2.show()  \n",
    "print(all_photos[170].shape)\n",
    "print(type(all_photos[170]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "#flatten them\n",
    "all_photosF = np.ndarray([255, 784])#255, 256*256*4\n",
    "for j, imgg in enumerate(all_photos):\n",
    "    all_photosF[j] = (imgg.flatten())\n",
    "    \n",
    "print(len(all_photosF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "#Debugginig\n",
    "print(type(all_photosF[5]))\n",
    "print(all_photosF[5].shape)\n",
    "# print(all_photosF[8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#labels(ground_truth) as one hot key\n",
    "all_gt =  np.zeros([255, 3])\n",
    "\n",
    "for i in range(255):\n",
    "    if i > 169:\n",
    "        all_gt[i][2] = 1\n",
    "    elif i > 84:\n",
    "        all_gt[i][1] = 1\n",
    "    else:\n",
    "        all_gt[i][0] = 1\n",
    "\n",
    "# print(all_gt[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 3)\n"
     ]
    }
   ],
   "source": [
    "#Training data(210) \n",
    "X_tr = np.ndarray([210,784])\n",
    "y_tr = np.ndarray([210,3])\n",
    "\n",
    "X_tr[0:70] = all_photosF[0:70] #first 70 lines\n",
    "X_tr[70:140] = all_photosF[85:155] #first 70 ellipses\n",
    "X_tr[140:210] = all_photosF[170:240] #first 70 diamonds\n",
    "\n",
    "y_tr[0:70] = all_gt[0:70]\n",
    "y_tr[70:140] = all_gt[85:155]\n",
    "y_tr[140:210] = all_gt[170:240]\n",
    "\n",
    "print(y_tr.shape)\n",
    "# print(y_tr[0:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 3)\n"
     ]
    }
   ],
   "source": [
    "# Validation data(45)\n",
    "X_v = np.ndarray([45,784])\n",
    "y_v = np.ndarray([45,3])\n",
    "\n",
    "X_v[0:15] = all_photosF[70:85]\n",
    "X_v[15:30] = all_photosF[155:170]\n",
    "X_v[30:45] = all_photosF[240:255]\n",
    "\n",
    "y_v[0:15] = all_gt[70:85]\n",
    "y_v[15:30] = all_gt[155:170]\n",
    "y_v[30:45] = all_gt[240:255]\n",
    "\n",
    "print(y_v.shape)\n",
    "# print(y_v[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "(?, 3)\n"
     ]
    }
   ],
   "source": [
    "#building the model\n",
    "#inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "#Paramaters\n",
    "W = tf.Variable(tf.zeros([784,3]))\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "#output\n",
    "y = tf.matmul(x,W) + b\n",
    "y_softmax = tf.nn.softmax(y)\n",
    "\n",
    "#Gorund truth\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "print(x.shape)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Compute Loss\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "#Update to improve this loss margin\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "#Now We can launch the model\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellapsed Time: \n",
      "0:00:20.825454\n"
     ]
    }
   ],
   "source": [
    "#train 1000 step\n",
    "from datetime import datetime\n",
    "start=datetime.now()\n",
    "\n",
    "for _ in range(10000):\n",
    "#     batch_xs, batch_ys = X_tr[i:i+3], y_tr[i:i+3]\n",
    "#     sess.run(train_step)\n",
    "    sess.run(train_step, feed_dict={x: X_tr, y_: y_tr})\n",
    "\n",
    "print(\"Ellapsed Time: \")\n",
    "print (datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844445\n"
     ]
    }
   ],
   "source": [
    "#Evaluating\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: X_v, y_: y_v})) #!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#converting it into CNN \n",
    "#Data augmentation\n",
    "#Where are my weights now?! \n",
    "#batches\n",
    "#check_ponits(every specific time ?!)\n",
    "#Save, Restore\n",
    "#Analysis (model summary and tensorboard)\n",
    "#Converting to cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Saving and creating checkpoints\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"chkpts/model_3n.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Restoring variables\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"chkpts/model_1n.ckpt\")\n",
    "    print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# momken ba2a ba3d ama a-restore el model a3mel test ezai ?!\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={x: X_v, y_: y_v}))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can easily specify the names and variables to save or load by passing to the tf.train.Saver() constructor either of the following:\n",
    "\n",
    "A list of variables (which will be stored under their own names).\n",
    "A Python dictionary in which keys are the names to use and the values are the variables to manage.\n",
    "Continuing from the save/restore examples shown earlier:\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", [3], initializer = tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", [5], initializer = tf.zeros_initializer)\n",
    "\n",
    "# Add ops to save and restore only `v2` using the name \"v2\"\n",
    "saver = tf.train.Saver({\"v2\": v2})\n",
    "\n",
    "# Use the saver object normally after that.\n",
    "with tf.Session() as sess:\n",
    "  # Initialize v1 since the saver will not.\n",
    "  v1.initializer.run()\n",
    "  saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "sound_file = './sound/finish.mp3'\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
