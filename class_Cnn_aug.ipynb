{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltim\n",
    "from PIL import Image as im\n",
    "import numpy as np\n",
    "import os \n",
    "import tensorflow as tf\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#reading \"Augmented\" images and data adjustment\n",
    "all_photos =  np.ndarray([2805, 28, 28, 1])#935*3, photo dims\n",
    "all_photos_names =  []\n",
    "print(all_photos.shape)\n",
    "\n",
    "#reading Lines\n",
    "for i, filename in enumerate(os.listdir(\"Line_TS\")):   \n",
    "    tmp = im.open(\"Line_TS/\" + filename)\n",
    "    tmp.thumbnail((28,28))\n",
    "    tmp2 = np.array(tmp.convert('L'))\n",
    "    all_photos[i] = tmp2.reshape((28,28,1))\n",
    "    all_photos_names.append(filename)\n",
    "\n",
    "#reading Ellipse\n",
    "for i, filename in enumerate(os.listdir(\"Ellipse_TS\")):\n",
    "    tmp = im.open(\"Ellipse_TS/\" + filename)\n",
    "    tmp.thumbnail((28,28))\n",
    "    tmp2 = np.array(tmp.convert('L'))\n",
    "    all_photos[i+85] = tmp2.reshape((28,28,1))\n",
    "    all_photos_names.append(filename)\n",
    "    \n",
    "#reading Diamonds\n",
    "for i, filename in enumerate(os.listdir(\"Diamond_TS\")):\n",
    "    tmp = im.open(\"Diamond_TS/\" + filename)\n",
    "    tmp.thumbnail((28,28))\n",
    "    tmp2 = np.array(tmp.convert('L'))\n",
    "    all_photos[i+170] = tmp2.reshape((28,28,1))\n",
    "    all_photos_names.append(filename)\n",
    "\n",
    "    \n",
    "print(len(all_photos_names))\n",
    "img2 = im.open(\"Line_TS/\" + all_photos_names[0])\n",
    "img2.show()\n",
    "print(all_photos[0].shape)\n",
    "print(type(all_photos[0]))\n",
    "\n",
    "img2 = im.open(\"Ellipse_TS/\" + all_photos_names[935])\n",
    "img2.show()\n",
    "print(all_photos[935].shape)\n",
    "print(type(all_photos[935]))\n",
    "\n",
    "img2 = im.open(\"Diamond_TS/\" + all_photos_names[1870])\n",
    "img2.show()  \n",
    "print(all_photos[1870].shape)\n",
    "print(type(all_photos[1870]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#flatten them\n",
    "all_photosF = np.ndarray([2805, 784])#2805, 28*28*1\n",
    "for j, imgg in enumerate(all_photos):\n",
    "    all_photosF[j] = (imgg.flatten())\n",
    "    \n",
    "print(len(all_photosF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#labels(ground_truth) as one hot key\n",
    "all_gt =  np.zeros([2805, 3])\n",
    "\n",
    "for i in range(2805):\n",
    "    if i > 1869:\n",
    "        all_gt[i][2] = 1\n",
    "    elif i > 934:\n",
    "        all_gt[i][1] = 1\n",
    "    else:\n",
    "        all_gt[i][0] = 1\n",
    "\n",
    "# print(all_gt[2800])\n",
    "print(all_gt[1870:2620])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Training data(2250) 750*3, Testing data(555) 185*3\n",
    "#750 1500 2250 , 185 370 555\n",
    "\n",
    "X_tr = np.ndarray([2250,784])\n",
    "y_tr = np.ndarray([2250,3])\n",
    "\n",
    "X_v = np.ndarray([555,784])\n",
    "y_v = np.ndarray([555,3])\n",
    "\n",
    "#================Line(all_photosF[0->934]) \n",
    "indexes = sample(range(0,935), 750)\n",
    "#print(len(indexes))\n",
    "# print( len(np.delete(all_photosF[1870:2805],indexes,axis=0)))\n",
    "\n",
    "X_tr[0:750] = all_photosF[indexes]\n",
    "y_tr[0:750] = all_gt[0:750]\n",
    "\n",
    "X_v[0:185] = np.delete(all_photosF[0:935],indexes,axis=0)\n",
    "y_v[0:185] = all_gt[0:185]\n",
    "\n",
    "#================Ellipse(all_photosF[935->1869])\n",
    "indexes = sample(range(0,935), 750)\n",
    "\n",
    "X_tr[750:1500] = all_photosF[indexes] \n",
    "y_tr[750:1500] = all_gt[935:1685]\n",
    "\n",
    "X_v[185:370] = np.delete(all_photosF[935:1870],indexes,axis=0)\n",
    "y_v[185:370] = all_gt[935:1120]\n",
    "\n",
    "#================Diamonds(all_photosF[1870->2804])\n",
    "indexes = sample(range(0,935), 750)\n",
    "\n",
    "X_tr[1500:2250] = all_photosF[indexes]\n",
    "y_tr[1500:2250] = all_gt[1870:2620]\n",
    "\n",
    "X_v[370:555] = np.delete(all_photosF[1870:2805],indexes,axis=0)\n",
    "y_v[370:555] = all_gt[1870:2055]\n",
    "\n",
    "# print(y_tr.shape)\n",
    "# # print(y_tr[0:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "#Gorund truth\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--Layer1\n",
    "#Conv, Batch_Noram, Relu, DropOut\n",
    "#kda eldropout tmam !!\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "batch_norm_conv1 = tf.contrib.layers.batch_norm(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_conv1 = tf.nn.relu(batch_norm_conv1)\n",
    "# h_conv1_drop = tf.nn.dropout(h_conv1, 0.5)\n",
    "#h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#--Layer2\n",
    "W_conv2 = weight_variable([3, 3, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "batch_norm_conv2 = tf.contrib.layers.batch_norm( conv2d(h_conv1, W_conv2) + b_conv2 )\n",
    "h_conv2 = tf.nn.relu( batch_norm_conv2)\n",
    "# h_conv2_drop = tf.nn.dropout(h_conv2, 0.8)\n",
    "# print (h_conv2_drop.shape)\n",
    "\n",
    "#--fc1\n",
    "W_fc1 = weight_variable([28 * 28 * 64, 256])\n",
    "b_fc1 = bias_variable([256])\n",
    "h_conv2_flat = tf.reshape(h_conv2, [-1, 28*28*64])\n",
    "batch_norm_fc1 = tf.contrib.layers.batch_norm( tf.matmul(h_conv2_flat, W_fc1) + b_fc1 )\n",
    "h_fc1 = tf.nn.relu(batch_norm_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "print (h_conv2_flat.shape)\n",
    "print(W_fc1)\n",
    "\n",
    "#--fc2\n",
    "W_fc2 = weight_variable([256, 64])\n",
    "b_fc2 = bias_variable([64])\n",
    "batch_norm_fc2 = tf.contrib.layers.batch_norm( tf.matmul(h_fc1_drop, W_fc2)  + b_fc2 )\n",
    "h_fc2 = tf.nn.relu(batch_norm_fc2)\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#Readout layer\n",
    "W_fc3 = weight_variable([64, 3])\n",
    "b_fc3 = bias_variable([3])\n",
    "\n",
    "y_conv = tf.matmul(h_fc2_drop, W_fc3) + b_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Evaluate error\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "#Update params\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "#compare with the ground truth\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "tic = time()\n",
    "\n",
    "for i in range(5000):\n",
    "    \n",
    "    for j in range(0, 2250, 75):\n",
    "        train_accuracy = accuracy.eval(feed_dict={ x: X_tr[j:j+75], y_: y_tr[j:j+75], keep_prob: 1.0})\n",
    "        train_step.run(feed_dict={x: X_tr[j:j+75], y_: y_tr[j:j+75], keep_prob: 0.5})\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        \n",
    "\n",
    "toc = time()\n",
    "print('take time: %s' %((toc - tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Evaluating !!!!!!!\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={x: X_v, y_: y_v, keep_prob: 1.0}))\n",
    "# print('test accuracy %g' % accuracy.eval(feed_dict={x: X_v, y_: y_v}))\n",
    "writer = tf.summary.FileWriter('./Model_Summary' , sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Saving and creating checkpoints\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"chkpts/model_1Cnn_aug_batch_drop.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Restoring variables\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"chkpts/model_1Cnn_aug_batch_drop.ckpt\")\n",
    "print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# momken ba2a ba3d ama a-restore el model a3mel test ezai ?!\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={x: X_v, y_: y_v}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "sound_file = './sound/finish.mp3'\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
