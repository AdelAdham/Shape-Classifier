{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltim\n",
    "from PIL import Image as im\n",
    "import numpy as np\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 256, 256, 4)\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "#reading images\n",
    "all_photos =  np.ndarray([255, 256, 256, 4])#85*3, photo dims\n",
    "all_photos_names =  []\n",
    "print(all_photos.shape)\n",
    "\n",
    "#reading Lines\n",
    "for i, filename in enumerate(os.listdir(\"Line_TS\")):\n",
    "    all_photos[i] = pltim.imread(\"Line_TS/\" + filename, format=\"bmp\")\n",
    "    all_photos_names.append(filename)\n",
    "\n",
    "#reading Ellipse\n",
    "for i, filename in enumerate(os.listdir(\"Ellipse_TS\")):\n",
    "    all_photos[i+85] = pltim.imread(\"Ellipse_TS/\" + filename, format=\"bmp\")\n",
    "    all_photos_names.append(filename)\n",
    "    \n",
    "#reading Lines\n",
    "for i, filename in enumerate(os.listdir(\"Diamond_TS\")):\n",
    "    all_photos[i+170] = pltim.imread(\"Diamond_TS/\" + filename, format=\"bmp\")\n",
    "    all_photos_names.append(filename)\n",
    "\n",
    "print(len(all_photos_names))\n",
    "img2 = im.open(\"Line_TS/\" + all_photos_names[0])\n",
    "img2.show()\n",
    "\n",
    "img2 = im.open(\"Ellipse_TS/\" + all_photos_names[85])\n",
    "img2.show()\n",
    "\n",
    "img2 = im.open(\"Diamond_TS/\" + all_photos_names[170])\n",
    "img2.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#labels(ground_truth) as one hot key\n",
    "all_gt =  np.zeros([255, 3])\n",
    "\n",
    "for i in range(255):\n",
    "    if i > 169:\n",
    "        all_gt[i][2] = 1\n",
    "    elif i > 84:\n",
    "        all_gt[i][1] = 1\n",
    "    else:\n",
    "        all_gt[i][0] = 1\n",
    "\n",
    "# print(all_gt[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 256, 256, 4)\n",
      "(210, 3)\n"
     ]
    }
   ],
   "source": [
    "#Training data(210) \n",
    "X_tr = np.ndarray([210,256, 256, 4])\n",
    "y_tr = np.ndarray([210,3])\n",
    "\n",
    "X_tr[0:70] = all_photos[0:70] #first 70 lines\n",
    "X_tr[70:140] = all_photos[85:155] #first 70 ellipses\n",
    "X_tr[140:210] = all_photos[170:240] #first 70 diamonds\n",
    "\n",
    "y_tr[0:70] = all_gt[0:70]\n",
    "y_tr[70:140] = all_gt[85:155]\n",
    "y_tr[140:210] = all_gt[170:240]\n",
    "\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "# print(X_tr[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 3)\n"
     ]
    }
   ],
   "source": [
    "# Validation data(45)\n",
    "X_v = np.ndarray([45, 256, 256, 4])\n",
    "y_v = np.ndarray([45,3])\n",
    "\n",
    "X_v[0:15] = all_photos[70:85]\n",
    "X_v[15:30] = all_photos[155:170]\n",
    "X_v[30:45] = all_photos[240:255]\n",
    "\n",
    "y_v[0:15] = all_gt[70:85]\n",
    "y_v[15:30] = all_gt[155:170]\n",
    "y_v[30:45] = all_gt[240:255]\n",
    "\n",
    "print(y_v.shape)\n",
    "# print(y_v[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 262144])\n",
    "x_image = tf.reshape(x, [-1, 256, 256, 4])\n",
    "\n",
    "#Gorund truth\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 256, 256, 64)\n",
      "(?, 4194304)\n",
      "Tensor(\"Variable_14/read:0\", shape=(4194304, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#--Layer1\n",
    "W_conv1 = weight_variable([5, 5, 4, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "batch_norm_conv1 = tf.contrib.layers.batch_norm(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_conv1 = tf.nn.relu(batch_norm_conv1)\n",
    "h_conv1_drop = tf.nn.dropout(h_conv1, 0.5)\n",
    "#h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#--Layer2\n",
    "W_conv2 = weight_variable([3, 3, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "batch_norm_conv2 = tf.contrib.layers.batch_norm( conv2d(h_conv1_drop, W_conv2) + b_conv2 )\n",
    "h_conv2 = tf.nn.relu( batch_norm_conv2)\n",
    "h_conv2_drop = tf.nn.dropout(h_conv2, 0.8)\n",
    "print (h_conv2_drop.shape)\n",
    "\n",
    "#--fc1\n",
    "W_fc1 = weight_variable([256 * 256 * 64, 256]) #256*256*4*64?!\n",
    "b_fc1 = bias_variable([256])\n",
    "h_conv2_flat = tf.reshape(h_conv2_drop, [-1, 256*256*64]) #256*256*4*64?!\n",
    "batch_norm_fc1 = tf.contrib.layers.batch_norm( tf.matmul(h_conv2_flat, W_fc1) + b_fc1 )\n",
    "h_fc1 = tf.nn.relu(batch_norm_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, 0.6)\n",
    "print (h_conv2_flat.shape)\n",
    "print(W_fc1)\n",
    "\n",
    "#--fc3\n",
    "W_fc2 = weight_variable([256, 64])\n",
    "b_fc2 = bias_variable([64])\n",
    "batch_norm_fc2 = tf.contrib.layers.batch_norm( tf.matmul(h_fc1_drop, W_fc2)  + b_fc2 )\n",
    "h_fc2 = tf.nn.relu(batch_norm_fc2)\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, 0.9)\n",
    "\n",
    "#Readout layer\n",
    "W_fc3 = weight_variable([64, 3])\n",
    "b_fc3 = bias_variable([3])\n",
    "\n",
    "y_conv = tf.matmul(h_fc2_drop, W_fc3) + b_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Evaluate error\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "#Update params\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#compare with the ground truth\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "tic = time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(4):\n",
    "                \n",
    "        if i % 2 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: X_tr, y_: y_tr})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            \n",
    "        #train_step.run(feed_dict={x: X_tr, y_: y_tr, keep_prob: 0.5}) how to not to use dropout in test?\n",
    "        train_step.run(feed_dict={x: X_tr, y_: y_tr})\n",
    "    \n",
    "toc = time()\n",
    "\n",
    "print('take time: %s' %((toc - tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Evaluating\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={x: X_v, y_: y_v}))\n",
    "    #writer = tf.summary.FileWriter('./Model_Summary' , sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Where are my weights now?! \n",
    "#batches\n",
    "#check_ponits(every specific time ?!) mkanha feen sa7?!\n",
    "#Save, Restore\n",
    "#Analysis (model summary and tensorboard)\n",
    "#Converting to cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Saving and creating checkpoints\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"chkpts/model_1n.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Restoring variables\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"chkpts/model_1n.ckpt\")\n",
    "    print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# momken ba2a ba3d ama a-restore el model a3mel test ezai ?!\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={x: X_v, y_: y_v}))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can easily specify the names and variables to save or load by passing to the tf.train.Saver() constructor either of the following:\n",
    "\n",
    "A list of variables (which will be stored under their own names).\n",
    "A Python dictionary in which keys are the names to use and the values are the variables to manage.\n",
    "Continuing from the save/restore examples shown earlier:\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", [3], initializer = tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", [5], initializer = tf.zeros_initializer)\n",
    "\n",
    "# Add ops to save and restore only `v2` using the name \"v2\"\n",
    "saver = tf.train.Saver({\"v2\": v2})\n",
    "\n",
    "# Use the saver object normally after that.\n",
    "with tf.Session() as sess:\n",
    "  # Initialize v1 since the saver will not.\n",
    "  v1.initializer.run()\n",
    "  saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "sound_file = './sound/finish.mp3'\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
