{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltim\n",
    "from PIL import Image as im\n",
    "import numpy as np\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 28, 28, 1)\n",
      "255\n",
      "(28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#reading images and data adjustment\n",
    "all_photos =  np.ndarray([255, 28, 28, 1])#85*3, photo dims\n",
    "all_photos_names =  []\n",
    "print(all_photos.shape)\n",
    "\n",
    "#reading Lines\n",
    "for i, filename in enumerate(os.listdir(\"Line_TS\")):   \n",
    "    tmp = im.open(\"Line_TS/\" + filename)\n",
    "    tmp.thumbnail((28,28))\n",
    "    tmp2 = np.array(tmp.convert('L'))\n",
    "    all_photos[i] = tmp2.reshape((28,28,1))\n",
    "    all_photos_names.append(filename)\n",
    "\n",
    "#reading Ellipse\n",
    "for i, filename in enumerate(os.listdir(\"Ellipse_TS\")):\n",
    "    tmp = im.open(\"Ellipse_TS/\" + filename)\n",
    "    tmp.thumbnail((28,28))\n",
    "    tmp2 = np.array(tmp.convert('L'))\n",
    "    all_photos[i+85] = tmp2.reshape((28,28,1))\n",
    "    all_photos_names.append(filename)\n",
    "    \n",
    "#reading Diamonds\n",
    "for i, filename in enumerate(os.listdir(\"Diamond_TS\")):\n",
    "    tmp = im.open(\"Diamond_TS/\" + filename)\n",
    "    tmp.thumbnail((28,28))\n",
    "    tmp2 = np.array(tmp.convert('L'))\n",
    "    all_photos[i+170] = tmp2.reshape((28,28,1))\n",
    "    all_photos_names.append(filename)\n",
    "\n",
    "print(len(all_photos_names))\n",
    "img2 = im.open(\"Line_TS/\" + all_photos_names[0])\n",
    "img2.show()\n",
    "print(all_photos[0].shape)\n",
    "print(type(all_photos[0]))\n",
    "\n",
    "img2 = im.open(\"Ellipse_TS/\" + all_photos_names[85])\n",
    "img2.show()\n",
    "print(all_photos[85].shape)\n",
    "print(type(all_photos[85]))\n",
    "\n",
    "img2 = im.open(\"Diamond_TS/\" + all_photos_names[170])\n",
    "img2.show()  \n",
    "print(all_photos[170].shape)\n",
    "print(type(all_photos[170]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "#flatten them\n",
    "all_photosF = np.ndarray([255, 784])#255, 256*256*4\n",
    "for j, imgg in enumerate(all_photos):\n",
    "    all_photosF[j] = (imgg.flatten())\n",
    "    \n",
    "print(len(all_photosF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#labels(ground_truth) as one hot key\n",
    "all_gt =  np.zeros([255, 3])\n",
    "\n",
    "for i in range(255):\n",
    "    if i > 169:\n",
    "        all_gt[i][2] = 1\n",
    "    elif i > 84:\n",
    "        all_gt[i][1] = 1\n",
    "    else:\n",
    "        all_gt[i][0] = 1\n",
    "\n",
    "# print(all_gt[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 3)\n"
     ]
    }
   ],
   "source": [
    "#Training data(210) \n",
    "X_tr = np.ndarray([210,784])\n",
    "y_tr = np.ndarray([210,3])\n",
    "\n",
    "X_tr[0:70] = all_photosF[0:70] #first 70 lines\n",
    "X_tr[70:140] = all_photosF[85:155] #first 70 ellipses\n",
    "X_tr[140:210] = all_photosF[170:240] #first 70 diamonds\n",
    "\n",
    "y_tr[0:70] = all_gt[0:70]\n",
    "y_tr[70:140] = all_gt[85:155]\n",
    "y_tr[140:210] = all_gt[170:240]\n",
    "\n",
    "print(y_tr.shape)\n",
    "# print(y_tr[0:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 3)\n"
     ]
    }
   ],
   "source": [
    "# Validation data(45)\n",
    "X_v = np.ndarray([45,784])\n",
    "y_v = np.ndarray([45,3])\n",
    "\n",
    "X_v[0:15] = all_photosF[70:85]\n",
    "X_v[15:30] = all_photosF[155:170]\n",
    "X_v[30:45] = all_photosF[240:255]\n",
    "\n",
    "y_v[0:15] = all_gt[70:85]\n",
    "y_v[15:30] = all_gt[155:170]\n",
    "y_v[30:45] = all_gt[240:255]\n",
    "\n",
    "print(y_v.shape)\n",
    "# print(y_v[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "#Gorund truth\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 64)\n",
      "(?, 50176)\n",
      "Tensor(\"Variable_4/read:0\", shape=(50176, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#--Layer1\n",
    "#Conv, Batch_Noram, Relu, DropOut\n",
    "#kda eldropout tmam !!\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "batch_norm_conv1 = tf.contrib.layers.batch_norm(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_conv1 = tf.nn.relu(batch_norm_conv1)\n",
    "h_conv1_drop = tf.nn.dropout(h_conv1, 0.5)\n",
    "#h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#--Layer2\n",
    "W_conv2 = weight_variable([3, 3, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "batch_norm_conv2 = tf.contrib.layers.batch_norm( conv2d(h_conv1_drop, W_conv2) + b_conv2 )\n",
    "h_conv2 = tf.nn.relu( batch_norm_conv2)\n",
    "h_conv2_drop = tf.nn.dropout(h_conv2, 0.8)\n",
    "print (h_conv2_drop.shape)\n",
    "\n",
    "#--fc1\n",
    "W_fc1 = weight_variable([28 * 28 * 64, 256])\n",
    "b_fc1 = bias_variable([256])\n",
    "h_conv2_flat = tf.reshape(h_conv2_drop, [-1, 28*28*64])\n",
    "batch_norm_fc1 = tf.contrib.layers.batch_norm( tf.matmul(h_conv2_flat, W_fc1) + b_fc1 )\n",
    "h_fc1 = tf.nn.relu(batch_norm_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, 0.6)\n",
    "print (h_conv2_flat.shape)\n",
    "print(W_fc1)\n",
    "\n",
    "#--fc3\n",
    "W_fc2 = weight_variable([256, 64])\n",
    "b_fc2 = bias_variable([64])\n",
    "batch_norm_fc2 = tf.contrib.layers.batch_norm( tf.matmul(h_fc1_drop, W_fc2)  + b_fc2 )\n",
    "h_fc2 = tf.nn.relu(batch_norm_fc2)\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, 0.9)\n",
    "\n",
    "#Readout layer\n",
    "W_fc3 = weight_variable([64, 3])\n",
    "b_fc3 = bias_variable([3])\n",
    "\n",
    "y_conv = tf.matmul(h_fc2_drop, W_fc3) + b_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Evaluate error\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "#Update params\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#compare with the ground truth\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.32381\n",
      "step 100, training accuracy 0.909524\n",
      "step 200, training accuracy 0.942857\n",
      "step 300, training accuracy 0.966667\n",
      "step 400, training accuracy 0.985714\n",
      "step 500, training accuracy 1\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 1\n",
      "step 800, training accuracy 1\n",
      "step 900, training accuracy 1\n",
      "step 1000, training accuracy 1\n",
      "step 1100, training accuracy 1\n",
      "step 1200, training accuracy 1\n",
      "step 1300, training accuracy 1\n",
      "step 1400, training accuracy 1\n",
      "step 1500, training accuracy 1\n",
      "step 1600, training accuracy 1\n",
      "step 1700, training accuracy 1\n",
      "step 1800, training accuracy 1\n",
      "step 1900, training accuracy 1\n",
      "take time: 14.941240994135539\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "tic = time()\n",
    "\n",
    "for i in range(2000):\n",
    "    \n",
    "    for j in range(0, 210, 70):\n",
    "        train_accuracy = accuracy.eval(feed_dict={ x: X_tr[j:j+70], y_: y_tr[j:j+70], keep_prob: 1.0})\n",
    "        train_step.run(feed_dict={x: X_tr[j:j+70], y_: y_tr[j:j+70], keep_prob: 0.5})\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        \n",
    "\n",
    "toc = time()\n",
    "print('take time: %s' %((toc - tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.911111\n"
     ]
    }
   ],
   "source": [
    "#Evaluating !!!!!!!\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={x: X_v, y_: y_v, keep_prob: 1.0}))\n",
    "# print('test accuracy %g' % accuracy.eval(feed_dict={x: X_v, y_: y_v}))\n",
    "writer = tf.summary.FileWriter('./Model_Summary' , sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Where are my weights now?! \n",
    "#batches\n",
    "#check_ponits(every specific time ?!) mkanha feen sa7?!\n",
    "#Save, Restore\n",
    "#Analysis (model summary and tensorboard)\n",
    "#Converting to cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Saving and creating checkpoints\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"chkpts/model_1Cnn.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Restoring variables\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"chkpts/model_1Cnn.ckpt\")\n",
    "    print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# momken ba2a ba3d ama a-restore el model a3mel test ezai ?!\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={x: X_v, y_: y_v}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"./sound/finish.mp3\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "sound_file = './sound/finish.mp3'\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
